{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cdbcdb2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c29dd2b140eba922e6ee82b9a597c97f",
     "grade": false,
     "grade_id": "cell-5d09d3504f685713",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<h1><center>Regularization</center></h1>\n",
    "\n",
    "<br>\n",
    "<center><font size=\"3\">This notebook is a part of teaching material for CS-EJ3311 - Deep Learning with Python</font></center>\n",
    "<center><font size=\"3\">24.10.-11.12.2022</font></center>\n",
    "<center><font size=\"3\">Aalto University & FiTech.io</font></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a8ecf4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "52f0dfa9457cd4b3f3a114ceb679c70c",
     "grade": false,
     "grade_id": "cell-0c52f82665f8597a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Deep learning methods use hypothesis spaces spanned by large parametrized signal flow charts, referred to as artificial neural networks (ANNs). Mathematically, an ANN is nothing but a parametrized non-linear map from input to output. The input of an ANN are the features of a data point, its output is typically the prediction for the label value. The relation (map) between input and output is non-linear and depends on tunable parameters (weights and biases). The parameters of an ANN are tuned or learnt by optimization methods that aim at minimizing the average loss on a training set. \n",
    "\n",
    "A key challenge in deep learning is that the average loss on a training set is not sufficient to guide the tuning of ANN parameters. Indeed, large ANNs have many different parameter configurations that result in a very small (essentially zero) training error. Looking only at the training error does not allow to decide which of these parameter configurations is the best (in terms of performance outside the training set). **Regularization** techniques use additional information, assumptions or constraints that allow to choose between different ANN parameter configurations that result in similar training errors. **Regularization** helps to avoid overfitting the training set and, in turn, to ensure the trained ANN does well on \"new\" data points which are not contained in the training set.\n",
    "\n",
    "\n",
    "A large class of regularization methods rests on an stability or smoothness assumption. This assumption requires the trained ANN to deliver similar predictions for data points with similar feature values. As any regularization technique, also the smoothness assumption can be implemented via each of the three main components of DL. In particular, this notebook teaches you the following regularization strategies: \n",
    "\n",
    "* **data** augmentation: we can augment the training set by cloning data points using slightly perturbed feature values but leave label values untouched. \n",
    "\n",
    "* **model** pruning: we can try to remove non-smooth maps from the hypothesis space, e.g., by placing constraints on the parameter configurations. \n",
    "\n",
    "* **loss** modification: we can add a regularization term to the original average loss on the training error. Examples for such a regularization term are squared Euclidean norm ($L2$ norm) or the $L1$ norm of the ANN parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b6e3817",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "657c3e144a96024f7fe6332ba9fc08ad",
     "grade": false,
     "grade_id": "cell-9623906a34f424df",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "@font-face {\n",
       "  font-family: 'Sanchez';\n",
       "  src: url('https://fonts.googleapis.com/css?family=Sanchez:400italic,400');\n",
       "}\n",
       "\n",
       "@import url('https://fonts.googleapis.com/css2?family=Sanchez&display=swap');\n",
       "\n",
       "* {\n",
       "  margin: 0;\n",
       "  padding: 0;\n",
       "  box-sizing: border-box;\n",
       "}\n",
       "\n",
       "*,\n",
       "*:before,\n",
       "*:after {\n",
       "\tbox-sizing: inherit;\n",
       "}\n",
       "\n",
       "body {\n",
       "font-family: -apple-system, BlinkMacSystemFont, \"Segoe UI\", Roboto, Helvetica,\n",
       "    Arial, sans-serif, \"Apple Color Emoji\", \"Segoe UI Emoji\", \"Segoe UI Symbol\";\n",
       "}\n",
       "\n",
       ".title-container {\n",
       "  text-align: left;\n",
       "}\n",
       "\n",
       ".title {\n",
       "  font-weight: 600;\n",
       "}\n",
       "\n",
       ".subtitle {\n",
       "  margin: 10px 0px;\n",
       "  color: #888888;\n",
       "  font-size: 25px;\n",
       "  transition: all 0.5s;\n",
       "}\n",
       "\n",
       ".main-container {\n",
       "  padding: 15px;\n",
       "}\n",
       "\n",
       ".card-container {\n",
       "  display: flex;\n",
       "  flex-wrap: wrap;\n",
       "  justify-content: space-between;\n",
       "}\n",
       "\n",
       ".card {\n",
       "  margin: 20px;\n",
       "  padding: 20px;\n",
       "  width: 100%;\n",
       "  min-height: 200px;\n",
       "  display: grid;\n",
       "  grid-template-columns: 1fr 1fr 1fr;\n",
       "  gap: 10px;\n",
       "  border-radius: 10px;\n",
       "  box-shadow: 0px 6px 10px rgba(0, 0, 0, 0.25);\n",
       "  transition: all 0.5s;\n",
       "}\n",
       "\n",
       ".card.small {\n",
       "  width: 50%;\n",
       "  min-height: 100px;\n",
       "  grid-template-columns: 1fr 1fr;\n",
       "}\n",
       "\n",
       ".card:hover {\n",
       "  box-shadow: 0px 6px 10px rgba(0, 0, 0, 0.4);\n",
       "  transform: scale(1.01);\n",
       "}\n",
       "\n",
       ".card__title {\n",
       "  grid-columnn-start: 1;\n",
       "  grid-columnn-end: -1;\n",
       "  font-weight: 400;\n",
       "  color: #ffffff;\n",
       "}\n",
       "\n",
       ".test-input {\n",
       "  grid-column-start: 1;\n",
       "  grid-column-end: 2;\n",
       "  color: #40413e;\n",
       "}\n",
       "\n",
       ".test-output {\n",
       "  grid-column-start: 2;\n",
       "  grid-column-end: 3;\n",
       "  color: #40413e;\n",
       "}\n",
       "\n",
       ".test-expected-output {\n",
       "  grid-column-start: 3;\n",
       "  grid-column-end: 4;\n",
       "  color: #40413e;\n",
       "}\n",
       "\n",
       ".card-failure {\n",
       "  background: radial-gradient(#fbc1cc, #fa99b2);\n",
       "}\n",
       "\n",
       ".card-failure .card__title::before {\n",
       "    display: inline-block;\n",
       "    margin-right: 5px;\n",
       "    font-style: normal;\n",
       "    font-variant: normal;\n",
       "    text-rendering: auto;\n",
       "    -webkit-font-smoothing: antialiased;\n",
       "    font-family: \"Font Awesome 5 Free\";\n",
       "    font-weight: 900;\n",
       "    content: \"\\f057\";\n",
       "}\n",
       "\n",
       ".card-success {\n",
       "  background: radial-gradient(#60efbc, #58d5c9);\n",
       "}\n",
       "\n",
       ".card-success .card__title::before {\n",
       "    display: inline-block;\n",
       "    margin-right: 5px;\n",
       "    font-style: normal;\n",
       "    font-variant: normal;\n",
       "    text-rendering: auto;\n",
       "    -webkit-font-smoothing: antialiased;\n",
       "    font-family: \"Font Awesome 5 Free\";\n",
       "    font-weight: 900;\n",
       "    content: \"\\f058\";\n",
       "}\n",
       "\n",
       ".card-info {\n",
       "  background: radial-gradient(#1fe4f5, #3fbafe);\n",
       "}\n",
       "\n",
       "@media (max-width: 1600px) {\n",
       "  .card-container {\n",
       "    justify-content: center;\n",
       "  }\n",
       "}\n",
       "\n",
       ".code-block {\n",
       "  padding: 5px;\n",
       "  background-color: #f3f7f7;\n",
       "  color: black;\n",
       "  border-radius: 10px;\n",
       "  box-shadow: 0px 6px 10px rgba(0, 0, 0, 0.25);\n",
       "}\n",
       "\n",
       "details {\n",
       "\tfont-size: 1rem;\n",
       "\tbox-shadow: 0 10px 15px -5px rgba(0, 0, 0, 0.1),\n",
       "\t\t0 10px 10px -5px rgba(0, 0, 0, 0.04);\n",
       "\twidth: 100%;\n",
       "\tbackground: #ffffff;\n",
       "\tborder-radius: 10px;\n",
       "\tposition: relative;\n",
       "}\n",
       "\n",
       "details:hover {\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".summary-title {\n",
       "    user-select: none;\n",
       "    margin-left: 5px;\n",
       "}\n",
       "\n",
       ".summary-content {\n",
       "    border: 2px solid #0C7B89;\n",
       "    cursor: default;\n",
       "    padding: 1em;\n",
       "    font-weight: 300;\n",
       "    font-size: 15px;\n",
       "    line-height: 1.5;\n",
       "}\n",
       "\n",
       ".wrap-up {\n",
       "    border: 2px solid #B41086;\n",
       "    cursor: default;\n",
       "    padding: 20px;\n",
       "    line-height: 1.5;\n",
       "    border-radius: 20px\n",
       "}\n",
       "\n",
       ".wrap-up-title {\n",
       "    font-size:20px;\n",
       "    color: #B41086;\n",
       "    font-weight: bold\n",
       "}\n",
       "\n",
       ".wrap-up-content {\n",
       "    font-size:14px;\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".info {\n",
       "    background-color: white;\n",
       "    border: 2px solid #0C7B89;\n",
       "    cursor: default;\n",
       "    padding: 10px;\n",
       "    line-height: 1.5;\n",
       "    border-radius: 20px\n",
       "}\n",
       "\n",
       ".info-title {\n",
       "    font-size: 20px;\n",
       "    color: #0C7B89;\n",
       "    font-weight: bold\n",
       "}\n",
       "\n",
       "summary {\n",
       "   color: white;\n",
       "   font-size: large;\n",
       "   font-weight: bold;\n",
       "   padding: 1em;\n",
       "   background-color: #0C7B89;\n",
       "   border-radius: 8px;\n",
       "   list-style: none;\n",
       "}\n",
       "\n",
       "details[open] summary {\n",
       "    border-radius: 8px 8px 0 0;\n",
       "}\n",
       "\n",
       "details[open] summary::before {\n",
       "  transform: rotate(90deg);\n",
       "  font-family: \"Font Awesome 5 Free\";\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       "details summary::before {\n",
       "  position: absolute;\n",
       "  will-change: transform;\n",
       "  transition: transform 300ms ease;\n",
       "  font-family: \"Font Awesome 5 Free\";\n",
       "  color: #fff;\n",
       "  font-size: 1.1rem;\n",
       "  content: \"\\f105\";\n",
       "  left: 0;\n",
       "  display: inline-block;\n",
       "  width: 1.6rem;\n",
       "  text-align: center;\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       "summary:focus {\n",
       "  outline: none;\n",
       "}\n",
       "\n",
       "summary::-webkit-details-marker {\n",
       "    display: none;\n",
       "}\n",
       "\n",
       ".ludwig {\n",
       "  position: relative;\n",
       "  padding-left: 1em;\n",
       "  border-left: 0.2em solid lighten( hsl(200, 40, 10), 40%);\n",
       "  font-family: 'Roboto', serif;\n",
       "  font-size: 1.3em;\n",
       "  line-height: 1.5em;\n",
       "  font-weight: 100;\n",
       "}\n",
       "\n",
       ".ludwig::before, .ludwig::after {\n",
       "  content: '\\201C';\n",
       "  font-family: 'Sanchez';\n",
       "  color: lighten( hsl(200, 40, 10), 40%);\n",
       "}\n",
       "\n",
       ".ludwig::after {\n",
       "  content: '\\201D';\n",
       "}\n",
       "\n",
       ".blockquote-container {\n",
       "  margin: 2em auto;\n",
       "}\n",
       "\n",
       "blockquote {\n",
       "  margin-bottom: 3em;\n",
       "}\n",
       "\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import load_styles\n",
    "\n",
    "# This MUST be the last line of this cell\n",
    "load_styles()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67dc9baa",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "63e0b8ba4682e6e175de31aa2dee28f0",
     "grade": false,
     "grade_id": "cell-84024cac19e49a13",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Learning goals\n",
    "\n",
    "\n",
    "In this notebook, you will learn \n",
    "\n",
    "* how to implement regularization by data augmentation\n",
    "* how one can use regularization to (smoothly) decrease the size of hypothesis space\n",
    "* how to implement regularization by adding a penalty term to the loss function\n",
    "\n",
    "\n",
    "## Additional  Reading\n",
    "\n",
    "- Chapter 5.4 \"Improving generalization\" of \"Deep Learning with Python\" by F.Chollet. \n",
    "- Chapter 11 \"Avoiding Overfitting Through Regularization\" of \"Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow\" by Aurélien Géron. \n",
    "- Chapter 7 of A.Jung, [\"Machine Learning: The Basics,\"](https://github.com/alexjungaalto/MachineLearningTheBasics/blob/master/MLBasicsBook.pdf) Springer, Sinagpore 2022. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f79f25d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b2036bed8ff6b133d36a67414d479f77",
     "grade": false,
     "grade_id": "cell-08988fd51fbf504a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<h1><center> Data augmentation  </center></h1>\n",
    "\n",
    "Consider a basic deep learning setup, where we train ANN parameters by minimizing its average loss on a training set consisting of $m$ labeled data points. Let us assume that we can measure the size of the hypothesis space spanned by the ANN using some number $d_{\\rm eff}$ that we might refer to as **effective dimension**. As a rule of thumb (cf. alex.jung@aalto.fi), the ANN training will be successful (not overfit) as soon as \n",
    "\n",
    "\n",
    "$$ m \\geq 10 d_{\\rm eff}. (Alex's RuleOfThumb) $$\n",
    "\n",
    "One way to combat overfitting is to collect more (raw) data points to increase $m$. However, this is not always feasible, be it due to budget constraints (need to pay people to label the data) or time constraints. Data augmentation generates new data points synthetically, avoiding the need for collecting new raw data. The idea is to exploit known symmetries in the features and labels of data points. As a case in point, consider the problem of detecting the presence of an object in an image. Here, we can generated new labeled images by rotating, cropping or changing pixel values slightly, since these don't change the class. Loosely speaking, \"a rotated cat image is still showing a cat\". "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc4ba12",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e17c3e9d6f93b057f93ee8f66daf0608",
     "grade": false,
     "grade_id": "cell-4529854767e5099f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"info\">\n",
    "    <div  class=\"info-title\"><i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i>&nbsp; Info</div><br>\n",
    "    <div class=\"wrap-up-content\">\n",
    "        <b>The effective dimension</b> of an infinite hypothesis space is a measure of its size. Loosely speaking, the effective dimension is equal to the number of \"independent\" tunable parameters of the model. These parameters might be the coefficients used in a linear map or the weights and bias terms of an ANN.\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23ece4d9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f7ca378729a88bf0a63c65d12197f1e1",
     "grade": false,
     "grade_id": "cell-9e595cb0747fca37",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np                    # library for numerical computations (vectors, matrices, tensors)\n",
    "import matplotlib.pyplot as plt       # library providing tools for plotting data \n",
    "import tensorflow as tf               # open source library for deep learning\n",
    "from tensorflow import keras          # library providing methods for defining and training ANN \n",
    "from tensorflow.keras import layers, regularizers \n",
    "from math import isclose\n",
    "\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8373414",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "42704be8a85f180106735777806b1169",
     "grade": false,
     "grade_id": "cell-53d0acd260c41939",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# set trainig = False when validating or submitting notebook\n",
    "# and set training = True, when training network\n",
    "training=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29464784",
   "metadata": {},
   "outputs": [],
   "source": [
    "training = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d223017c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "78e32c0b41abe42af42f7f3942d6b399",
     "grade": true,
     "grade_id": "cell-ded5c81a61c805ba",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# this is a hidden cell to set training=False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f850469",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0c575a5be483107f63368bc65af9fed0",
     "grade": false,
     "grade_id": "cell-6b8af07969d4ed56",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In this notebook we use the subset of [Fashion-MNIST ](https://www.tensorflow.org/datasets/catalog/fashion_mnist) dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "500ba97d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f6e711a589e3215185bc75dd0f430cea",
     "grade": false,
     "grade_id": "cell-fa16a7540e003a4b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training and validation examples (60000, 28, 28)\n",
      "Number of test examples (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "# load dataset\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "(trainval_images, trainval_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "# shape of train and test image\n",
    "print(f'Number of training and validation examples {trainval_images.shape}')\n",
    "print(f'Number of test examples {test_images.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddaa47ec",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fef9e1afbaf0f89e5ed8b7537b96ee1f",
     "grade": false,
     "grade_id": "cell-4d841dca9105b7e3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# select subset of trainval_images and trainval_labels\n",
    "X_trainval = trainval_images[:16000]\n",
    "y_trainval = trainval_labels[:16000]\n",
    "\n",
    "# select whole test set\n",
    "X_test = test_images\n",
    "y_test = test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "796c669e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "765d50b3d42c5be01cd170049cb49543",
     "grade": false,
     "grade_id": "cell-cb3ed5d2770cec8f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# flatten 2D image to 1D feature vector \n",
    "X_trainval = X_trainval.reshape(-1, 28 * 28)\n",
    "X_test = test_images.reshape(-1, 28 * 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f7d711a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "de8a43caf233efdb61962decabace322",
     "grade": false,
     "grade_id": "cell-cceae7b49f4df17a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Normalize data to have feature values between 0 and 1\n",
    "X_trainval = X_trainval/ 255.0\n",
    "X_test = X_test/ 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149acd39",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2643f9706f27b5546ec877136f77ee0e",
     "grade": false,
     "grade_id": "cell-4e716c109ef59c78",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a id='St1'></a>\n",
    "<div class=\" alert alert-warning\">\n",
    "    <h3><b>Student task.</b> Build \"base\" ANN without regularization.</h3>  \n",
    "    \n",
    "    \n",
    "Your task is to build (we will do compiling and training model later) a following ANN for **Fashion-MNIST classification dataset**:\n",
    "    \n",
    "- Dense layer with 128 units and ReLU activation, input_shape=(784,)\n",
    "- Dense layer with 64 units and ReLU activation\n",
    "- Dense layer with 32 units and ReLU activation\n",
    "- Dense output layer with 10 units and softmax activation function   \n",
    "</div>\n",
    "\n",
    "Note: Ignore warning \"This TensorFlow binary is optimized with oneAPI ...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7b4fc95",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5e2c21c1bd54d5aa58e47a354bc773d4",
     "grade": false,
     "grade_id": "cell-c3785933d1fed4d7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 111,146\n",
      "Trainable params: 111,146\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-23 10:52:20.752029: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "model_base = tf.keras.models.Sequential([tf.keras.layers.Dense(128, activation=\"relu\", input_shape=(784,)),\n",
    "                                        tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "                                        tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "                                        tf.keras.layers.Dense(10, activation=\"softmax\")]\n",
    "                                       )\n",
    "model_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93cb682c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0e613be0ca756cc6e70fd9db58f6d535",
     "grade": false,
     "grade_id": "cell-e97b3912fc5d64af",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity checks passed!\n"
     ]
    }
   ],
   "source": [
    "# Perform some sanity checks on the solution\n",
    "assert len(model_base.layers) == 4, \"There should be 4 layers!\"\n",
    "assert model_base.layers[0].input_shape[1:] == (784,), \"Input shape is wrong\"\n",
    "assert model_base.layers[0].output_shape[1:] == (128,), \"Output shape is wrong\"\n",
    "\n",
    "print(\"Sanity checks passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3face479",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "17a0649402d3ca3541d46e28588fb076",
     "grade": true,
     "grade_id": "cell-fb4d2f9d44312516",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# this cell is for tests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db40d6d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9b03daee22ee066d4493978bf1cb02fc",
     "grade": false,
     "grade_id": "cell-9279793ee15c1a49",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a id='St1'></a>\n",
    "<div class=\" alert alert-info\">\n",
    "    <h3><b>Demo.</b> Data augmentation: Image rotation and flip.</h3>  \n",
    "\n",
    "Here we implement data augmentation technique for images by rotating and flipping original images.\n",
    "\n",
    "We will use Keras [Image augmentation layers](https://keras.io/api/layers/preprocessing_layers/image_augmentation/) `RandomFlip` and `RandomRotation`.\n",
    "    \n",
    "`RandomFlip` layer flips an image horizontally, vertically or both, according to its argument `mode` (takes strings \"horizontal\", \"vertical\", or \"horizontal_and_vertical\" as input).\n",
    "    \n",
    "`RandomRotation` layer rotates image by a random angle defined by argument `factor`. For example, `factor=0.2` results in an output rotating by a random amount in the range `[-20% * 2pi, 20% * 2pi]`.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dfcfe1ac",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fc267d444dfa19ebd08cd993bbae1a93",
     "grade": false,
     "grade_id": "cell-00c110c7a0b9d2ab",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create data augmentation layer\n",
    "data_aug_layer = tf.keras.Sequential([\n",
    "            # input is a 3D array - image (hight, width, channels)\n",
    "            layers.RandomFlip(\"horizontal\", input_shape=(28, 28, 1), seed=42),\n",
    "            layers.RandomRotation(0.1, seed=42),\n",
    "            ])\n",
    "\n",
    "# select first data point of the test set \n",
    "# reshape to (n.o. samples, hight, width, channels)\n",
    "X_no_aug = X_test[0].reshape(1, 28, 28, 1)\n",
    "# apply data augmentation to selected image\n",
    "X_aug    = data_aug_layer(X_no_aug)\n",
    "\n",
    "fig, ax = plt.subplots(1,2)\n",
    "ax[0].imshow(X_no_aug[0], cmap='binary') \n",
    "ax[1].imshow(X_aug[0], cmap='binary') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7ea6dff",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8389a10a520efdbc9dfa655dde8ca860",
     "grade": false,
     "grade_id": "cell-88c13bfe629d6ceb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# add data augmentation layer to the model\n",
    "model_data_aug = keras.Sequential([\n",
    "            data_aug_layer,\n",
    "            # flatten input as the output of data_aug_layer is of shape (n.o. samples, hight, width, channels)\n",
    "            # and for Dense layers we need shape (n.o. samples, features)\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(128, activation='relu'),\n",
    "            layers.Dense(64, activation='relu'),\n",
    "            layers.Dense(32, activation='relu'),\n",
    "            layers.Dense(10, activation='softmax')\n",
    "            ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adba9f6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f3536976e558254fc3cc8dec3a5ed8c3",
     "grade": false,
     "grade_id": "cell-53fa3fea78b348d1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a id='St1'></a>\n",
    "<div class=\" alert alert-info\">\n",
    "    <h3><b>Demo.</b> Data augmentation: Adding Gaussian noise to the image.</h3>  \n",
    "\n",
    "Data augmentation can be applied to the data types other than images by slighly disturbing original feature values, i.e. by adding some noise to the original data.\n",
    "    \n",
    "Below, we add Gaussian noise by using [GaussianNoise](https://keras.io/api/layers/regularization_layers/gaussian_noise/) layer. The argument `stddev` is a float value defining standard deviation of the noise distribution.\n",
    "    \n",
    "GaussianNoise layer is only active at a training time, thus we need to set argument `training=True` in order to add noise to the image and plot the result.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3f3b09f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5fd2fc0c71acce448c6b4c34845a1998",
     "grade": false,
     "grade_id": "cell-f52780a576fb3c39",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create data augmentation layer\n",
    "noise_layer = tf.keras.Sequential([\n",
    "            layers.GaussianNoise(stddev=0.01, input_shape=(784,))\n",
    "            ])\n",
    "\n",
    "# select first data point of the test set and reshape (for plotting)\n",
    "X_no_noise = X_test[0].reshape(28, 28, 1)\n",
    "# apply data augmentation to the first data point of the test set\n",
    "X_noise = noise_layer(X_test[0], training=True)\n",
    "# reshape (for plotting)\n",
    "X_noise = X_noise.numpy().reshape(28, 28, 1)\n",
    "\n",
    "fig, ax = plt.subplots(1,2)\n",
    "ax[0].imshow(X_no_noise, cmap='binary') \n",
    "ax[1].imshow(X_noise, cmap='binary') \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd9df30a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c83c89de546827666adca3b02cbd8a5b",
     "grade": false,
     "grade_id": "cell-3e21aba96b44748a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# add data augmentation layer to the model\n",
    "model_noise = keras.Sequential([\n",
    "            # add GaussianNoise layer\n",
    "            noise_layer,\n",
    "            layers.Dense(128, activation='relu'),\n",
    "            layers.Dense(64, activation='relu'),\n",
    "            layers.Dense(32, activation='relu'),\n",
    "            layers.Dense(10, activation='softmax')\n",
    "            ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e7ce64",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8e40325b5ad0522b2874bb49417e7761",
     "grade": false,
     "grade_id": "cell-a8a9a6a925d004f5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Dropout\n",
    "\n",
    "Data augmentation methods perturb features or labels of existing data points to obtain new (synthetic) data points. These perturbations include geometric transformations for image data or adding small amounts of noise to features of the data points. Dropout is another example for a perturbation technique that is well-suited for the training of ANNs. Instead of manipulating the features of a data point, dropout perturbs the activations of an ANN (i.e. output of the hidden neurons). In particular, as its name suggests, dropout randomly chooses a subset of neurons whose output is set to zero. As explained in the paper by X. Bouthillier, K. Konda, P. Vincent, R. Memisevic  \"Dropout as data augmentation\":\n",
    "\n",
    "<blockquote>\n",
    "Dropout is interpreted as bagging a large number of models sharing parameters. We show that using dropout in a network can also be interpreted as a kind of data augmentation in the input space without domain knowledge. We present an approach to projecting the dropout noise within a network back into the input space, thereby generating augmented versions of the training data, and we show that training a deterministic network on the augmented samples yields similar results. Finally, we propose a new dropout noise scheme based on our observations and show that it improves dropout results without adding significant computational cost.\n",
    "</blockquote>\n",
    "\n",
    "<img src=\"../../../coursedata/Regularization/dropout.png\" />\n",
    "\n",
    "More about dropout in [Andrew Ng video](https://www.youtube.com/watch?v=D8PJAL-MZv8)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1353473a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3b9be4b99a01d2cdf7dac1c8145a9b49",
     "grade": false,
     "grade_id": "cell-eca21715a3844334",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a id='St1'></a>\n",
    "<div class=\" alert alert-info\">\n",
    "    <h3><b>Demo.</b>  Data augmentation: ANN with Dropout Layers.</h3>  \n",
    "\n",
    "In Keras, dropout technique is implemented with [`Dropout` layer](https://keras.io/api/layers/regularization_layers/dropout/). The `Dropout` layer randomly sets its input units to 0 with a frequency defined by arg `rate` at each step during training time, which helps prevent overfitting. Inputs not set to 0 are scaled up by 1/(1 - `rate`) such that the sum over all inputs is unchanged.\n",
    "\n",
    "Note that the Dropout layer only applies during training (when using `model.fit()`), but not during inference (when using `model.evaluate()`).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df7b2f55",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "25e027421a7d7d8a868d21564b88fc1d",
     "grade": false,
     "grade_id": "cell-1bc08c9099afdfb7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# rate arg: Float between 0 and 1. Fraction of the input units to drop\n",
    "drate = 0.1\n",
    "\n",
    "model_dropout = keras.Sequential([\n",
    "    layers.Dense(128, activation='relu',input_shape=(784,)),\n",
    "    layers.Dropout(drate),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(drate),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dropout(drate),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c624d9a3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "155921ac619650517240cf99e29dfd24",
     "grade": false,
     "grade_id": "cell-ddb3fc1b47bc8701",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a id='St1'></a>\n",
    "<div class=\" alert alert-warning\">\n",
    "    <h3><b>Student task.</b> Compile and Train ANNs.</h3>  \n",
    "\n",
    "Use models from a list `models` and Fashion-MNIST dataset to classify 28x28 pixels grayscale images into 10 different classes, corresponding to specific fashion item:\n",
    "\n",
    "- For each model in a list `models` (models' architectures were defined above), compile and train the model. \n",
    "- Use optimizer - RMSprop, loss - `sparse_categorical_crossentropy` and  metrics -  `sparse_categorical_accuracy`. \\\n",
    "Training parameters: `history = model.fit(X_trainval, y_trainval, validation_split=0.2, batch_size=32, epochs=20)`.\n",
    " \n",
    "- Store history object for each model in a list `history_log`. \n",
    "- Save trained model as `model_name_here.h5`. Corresponding model names are retrieved from `model_names` list.\n",
    "    \n",
    "Note, that for the model `model_data_aug` the shape of the input should be $(m,28,28,1)$, i.e. reshape input features to (-1,28,28,1).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f223d7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7d267d3392672b170d852ba22c48b952",
     "grade": false,
     "grade_id": "cell-6b7ff27608c0a4b3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\" alert alert-danger\">\n",
    "    <h3 align='center'>Test accuracy should be $\\geq$ 0.80 for all models.</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9603a991",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "04d8cd79cb1d243516d402d420bdbbf9",
     "grade": false,
     "grade_id": "cell-bfbf4cdbf0509638",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# list of ANNs without and with data augmentation\n",
    "models = [model_base, model_data_aug, model_noise, model_dropout]\n",
    "\n",
    "# use this list when saving model\n",
    "model_names = ['model_base', 'model_data_aug', 'model_noise', 'model_dropout']\n",
    "\n",
    "# list to store training history\n",
    "history_log = []\n",
    "\n",
    "if training:\n",
    "    # YOUR CODE HERE\n",
    "    # loop through `model_names`  and `models` lists to get model name and model itself\n",
    "    for i, (model, model_name) in enumerate(zip(models, model_names)):\n",
    "        model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer='RMSprop',\n",
    "              metrics=[\"sparse_categorical_accuracy\"])\n",
    "        if i == 1:\n",
    "            history = model.fit(X_trainval.reshape(-1, 28, 28, 1), y_trainval, validation_split=0.2, batch_size=32, epochs=20)\n",
    "        else: \n",
    "            history = model.fit(X_trainval, y_trainval, validation_split=0.2, batch_size=32, epochs=20)\n",
    "            \n",
    "        history_log.append(history)\n",
    "        save_name = model_name + \".h5\"\n",
    "        model.save(save_name)\n",
    "        \n",
    "else:\n",
    "    model_base     = tf.keras.models.load_model(\"model_base.h5\")\n",
    "    model_data_aug = tf.keras.models.load_model(\"model_data_aug.h5\")\n",
    "    model_noise    = tf.keras.models.load_model(\"model_noise.h5\")\n",
    "    model_dropout  = tf.keras.models.load_model(\"model_dropout.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ce0216d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c55ee97a3fbddb9f6f687dc8c424b93d",
     "grade": false,
     "grade_id": "cell-b9f6901f24bdf036",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-23 10:52:22.816790: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model - Accuracy on test dataset:  0.8601\n",
      "Flip & Rotation - Accuracy on test dataset:  0.8117\n",
      "Noise - Accuracy on test dataset:  0.8603\n",
      "Dropout - Accuracy on test dataset:  0.8590\n"
     ]
    }
   ],
   "source": [
    "# evaluate trained models\n",
    "\n",
    "_, test_accuracy = model_base.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Base model - Accuracy on test dataset: {test_accuracy: .4f}')\n",
    "\n",
    "_, test_accuracy = model_data_aug.evaluate(X_test.reshape(-1,28,28,1), y_test, verbose=0)\n",
    "print(f'Flip & Rotation - Accuracy on test dataset: {test_accuracy: .4f}')\n",
    "\n",
    "_, test_accuracy = model_noise.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Noise - Accuracy on test dataset: {test_accuracy: .4f}')\n",
    "\n",
    "_, test_accuracy = model_dropout.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Dropout - Accuracy on test dataset: {test_accuracy: .4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f39dae9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7e54de1d5de83626afe16fea701dbeac",
     "grade": false,
     "grade_id": "cell-70c6b961c2372331",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Sanity checks\n",
    "\n",
    "# Load saved models\n",
    "model_base     = tf.keras.models.load_model(\"model_base.h5\")\n",
    "model_data_aug = tf.keras.models.load_model(\"model_data_aug.h5\")\n",
    "model_noise    = tf.keras.models.load_model(\"model_noise.h5\")\n",
    "model_dropout  = tf.keras.models.load_model(\"model_dropout.h5\")\n",
    "\n",
    "# Check n.o. layers\n",
    "assert len(model_base.layers) == 4, \"`model_base` should have 4 layers!\"\n",
    "assert len(model_data_aug.layers) == 6, \"`model_data_aug` should have 6 layers!\"\n",
    "assert len(model_noise.layers) == 5, \"`model_noise` should have 5 layers!\"\n",
    "assert len(model_dropout.layers) == 7, \"`model_dropout` should have 7 layers!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e3140ea",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "acc24497eee9f472198f91b77b350823",
     "grade": true,
     "grade_id": "cell-9dc507c1488a5008",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# cell for hidden test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9dd8de86",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c89075ad151252d3aaffcdd721dd20b3",
     "grade": true,
     "grade_id": "cell-b161a203baff4d2f",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# cell for hidden test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "063ae07b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e8de151e9741adf36f25682323763cc8",
     "grade": true,
     "grade_id": "cell-6e91ce0c5a795326",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# cell for hidden test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "238d6d74",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f208ab1f411c9aadf71c62e94a7dc847",
     "grade": true,
     "grade_id": "cell-432da91e084497fd",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# cell for hidden test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f6e06598",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bf869c3c6165445d5521cf98a4e4b542",
     "grade": false,
     "grade_id": "cell-fd80297eb81ec443",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "if training:\n",
    "    fig, axes = plt.subplots(1,4, sharey=True, figsize=(14,4))\n",
    "    title = ['base', 'rotation & flip', 'noise', 'dropout']\n",
    "\n",
    "    ax = axes.flat\n",
    "    for i, history in enumerate(history_log):\n",
    "        ax[i].plot(history.history['sparse_categorical_accuracy'])\n",
    "        ax[i].plot(history.history['val_sparse_categorical_accuracy'])\n",
    "        ax[i].spines[\"top\"].set_visible(False)\n",
    "        ax[i].spines[\"right\"].set_visible(False)\n",
    "        ax[i].set_title(title[i], fontsize=18)\n",
    "        ax[i].grid()\n",
    "\n",
    "    ax[0].set_xlabel('epoch', fontsize=14)\n",
    "    ax[0].set_ylabel('Accuracy', fontsize=14)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.legend(['train', 'val'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fbf67a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2aba04a81940a9588d9a868681bba894",
     "grade": false,
     "grade_id": "cell-624737bf1bcde921",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We can see that data augmentation with image rotation and flipping worsened the model trained compared to base model. Adding noise to the data lead to similar results as the base model and applying dropout prevented overfitting, but didn't improve test accuracy significantly. In order to improve validation and test accuracy we have to adjust regularization hyperparameters, i.e. do hyperparameter tuning. For example, increasing number of epochs for a model with dropout layers or adjusting the value of `stddev` argument of `GaussianNoise` layer may lead to better results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce2e5fc",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5a00a2d9c068f22e19d3e309a13d6ca4",
     "grade": false,
     "grade_id": "cell-c0f2eff61e5e2f84",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<h1><center>Model pruning</center></h1>\n",
    "\n",
    "According to the \"RuleOfThumb\" above, instead of increasing the size of the training set, we can also try to reduce the effective dimension of the ANN hypothesis space. In other words, we can avoid overfittng by using a smaller hypothesis space over which we search during training. Maybe the most obvious way to reduce the hypothesis space is to make the ANN smaller by removing hidden layers. Another option is to fix or \"freeze\" the parameters (weights, bias terms) of some of the layers. This approach is known as **transfer learning**. We next study **early stopping** as a more subtle means to prune the hypothesis space (model) of an ANN. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ac587a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "36a4639ce4d0f14b1dd2f50f29793a2c",
     "grade": false,
     "grade_id": "cell-f18e33c7d35a425c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Early stopping\n",
    "\n",
    "Nominally, the hypothesis space (or model) associated with a given ANN is constituted by all maps $h: \\mathbf{x} \\mapsto h(\\mathbf{x})$ that can be obtained from different choices for its parameters $\\mathbf{w}$. These parameters consist of the bias and (input) weights for each neurons in the ANN. Early stopping implements this pruning by limiting the number of gradient descent steps executed during the training. The training of an ANN typically starts from initial choice or guess $\\mathbf{w}^{(0)}$ which is then iteratively improved using some gradient descent method, $\\mathbf{w}^{(k+1)} = {\\rm SomeUpdateRule} \\big\\{ \\mathbf{w}^{(k)} \\big\\}$. Early stopping constraints the hypothesis space by stopping this update after a relatively small number of iterations.\n",
    "\n",
    "<img src=\"https://production-media.paperswithcode.com/methods/Screen_Shot_2020-05-28_at_12.59.56_PM_1D7lrVF.png\" width=\"600\"/>\n",
    "</br>\n",
    "\n",
    "More about data augmentation and early stopping in [Andrew Ng video](https://www.youtube.com/watch?v=BOCLq2gpcGU)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1a4ba6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "50a42b04042fca3d1310228ab9c35326",
     "grade": false,
     "grade_id": "cell-9328977ad9234183",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<h1><center>Loss modification</center></h1>\n",
    "\n",
    "\n",
    "## Parameter norm penalties\n",
    "\n",
    "One type of regularization techniques is parameter norm penalties. For example, $L1$ and $L2$ norm regularization, in which model is trained by minimizing a cost function that penalizes the large norm values of a model's parameters. Both of these alternatives are based on the premise that the complexity of a predictor increases with the magnitude of its parameters.\n",
    "\n",
    "\n",
    "The cost function that is minimized when training a regularized model $h$ is composed of the training loss and an additional **penalty term**:\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    " \\mathcal{E}(h) = \\underbrace{\\underbrace{(1/m_{t}) \\sum_{\\big(\\mathbf{x}^{(i)},y^{(i)}\\big) \\in \\mathbb{X}^{(t)}} \\mathcal L \\big( (x^{(i)}, y^{(i)}), h \\big)}_{\\mbox{ training loss}} + \\underbrace{\\alpha \\mathcal{R}(h)}_{\\mbox{anticipated increase of error (loss) on new data}}}_{\\mbox{ estimate (approximation) of test error }}\n",
    "\\end{equation}\n",
    "\n",
    "The central idea of regularization is that the penalized cost function is minimized by a less complex predictor than the average loss. Thus, a model trained using the penalized cost function should, in general, have better generalization capabilities provided that the penalty term is well chosen. \n",
    "\n",
    "The penalty term itself is composed of two factors - a **regularization term** $\\mathcal{R}(h)$ and a scaling factor $\\alpha$. The former quantifies a function's complexity, and the latter scales the penalty by a specified factor. Effectively, $\\alpha$ **offers a trade-off between the prediction error (training loss) incurred on the training data and the complexity of a predictor**. Large $\\alpha$ favor less complex predictor functions, while small $\\alpha$ put more emphasis on obtaining a small training loss.\n",
    "\n",
    "\n",
    "In order to implement regularization in practice, we need to choose a regularization term $\\mathcal{R}$ that quantifies the complexity of predictor functions in an appropriate way. Two widely used choices are the $L1$ norm \n",
    "\n",
    "\\begin{equation}\n",
    "\\|\\mathbf{w} \\|_1 = \\sum_{i=1}^n |w_i|= |w_1| + |w_2| + \\ldots + |w_n|\n",
    "\\end{equation}\n",
    "\n",
    "and the squared $L2$ norm\n",
    "\n",
    "\\begin{equation}\n",
    "\\|\\mathbf{w} \\|_2^2 = \\sum_{i=1}^n w_i^2 = w_1^2 + w_2^2 + \\ldots + w_n^2.\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "$L2$ norm harshly penalizes predictors with large weights, while $L1$ norm does not square the weights in the penalty, and thus, both large and small weights are penalized proportionately.\n",
    "\n",
    "\n",
    "More about norm penalties in [Andrew Ng video](https://www.youtube.com/watch?v=6g0t3Phly2M)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9067119b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bf80961b1c2dbbd623918b866747f833",
     "grade": false,
     "grade_id": "cell-67327cd2a2bd7897",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a id='St1'></a>\n",
    "<div class=\" alert alert-info\">\n",
    "    <h3><b>Demo.</b> $L1$ regularization.</h3>  \n",
    "\n",
    "In Keras we can add norm penalties to ANN weights and biases by passing regularizer to arguments `kernel_regularizer` and `bias_regularizer` of a keras layer. \n",
    "    \n",
    "Below we apply $L1$ regularization to weights of feed-forward ANN with Keras [layer weight regularizers](https://keras.io/api/layers/regularizers/). We use `regularizers.L1()` with scaling factor $\\alpha=1e-4$ as regularizer for model's weights.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bf7de64e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "74cdbfcde97515ec695ec40f8d9592e6",
     "grade": false,
     "grade_id": "cell-99c872184389b430",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# scaling factor alpha\n",
    "alpha_l1 = 1e-4\n",
    "\n",
    "model_l1 = keras.Sequential([\n",
    "    layers.Dense(128, activation='relu',input_shape=(784,),\n",
    "                kernel_regularizer = regularizers.L1(alpha_l1)),\n",
    "    layers.Dense(64, activation='relu', \n",
    "                kernel_regularizer = regularizers.L1(alpha_l1)),\n",
    "    layers.Dense(32, activation='relu',\n",
    "                kernel_regularizer = regularizers.L1(alpha_l1)),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89a7306",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "527334b18ab93dac8f4d04c8bde500d5",
     "grade": false,
     "grade_id": "cell-d08b7eb6a973de4d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a id='St1'></a>\n",
    "<div class=\" alert alert-warning\">\n",
    "    <h3><b>Student task.</b> $L2$ regularization.</h3>  \n",
    "\n",
    "Modify code snippet above and apply $L2$ regularization with scaling factor alpha=1e-4 instead of $L1$ regularization. See Keras [documentation](https://keras.io/api/layers/regularizers/#l2-class).\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bb77e5a2",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "843de3ede3f0beff83031400191a0764",
     "grade": false,
     "grade_id": "cell-6da7ef0b9f370844",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# scaling factor alpha\n",
    "alpha_l2 = 1e-4\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "model_l2 = keras.Sequential([\n",
    "    layers.Dense(128, activation='relu',input_shape=(784,),\n",
    "                kernel_regularizer = regularizers.L2(alpha_l2)),\n",
    "    layers.Dense(64, activation='relu', \n",
    "                kernel_regularizer = regularizers.L2(alpha_l2)),\n",
    "    layers.Dense(32, activation='relu',\n",
    "                kernel_regularizer = regularizers.L2(alpha_l2)),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "72d3d952",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8fe9375bf3d2a22a520babbc1d672f30",
     "grade": false,
     "grade_id": "cell-9cafb3d534befa6b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity checks passed!\n"
     ]
    }
   ],
   "source": [
    "# Perform some sanity checks on the solution\n",
    "assert len(model_l2.layers) == 4, \"There should be 4 layers!\"\n",
    "assert model_l2.layers[0].get_config()['kernel_regularizer']['class_name'] == 'L2', \"L2 regularization is missing!\"\n",
    "\n",
    "print(\"Sanity checks passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6cefdc85",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7f7388c12627e47ecc2c8021e32b3008",
     "grade": true,
     "grade_id": "cell-26983a222ff25ca2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# cell for hidden test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f17bfc4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0afc78bfba577c7ffd37e58b134e350f",
     "grade": false,
     "grade_id": "cell-b060d65c50e9e7b1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Hyperparameter tuning (choosing $\\alpha$)\n",
    "\n",
    "The $\\alpha$ factor in the regularized cost function is a **hyperparameter** of the regularized model. In contrast to **model parameters**, hyperparameters are not optimized by training the model but must be defined in advance. The hyperparameters' values are typically chosen by selecting the value from a set of candidates that results in the lowest validation error for the trained model. This process is called **hyperparameter tuning** and can be seen as a case of model selection, in which the models differ by the values of the hyperparameters.\n",
    "\n",
    "The hyperparameter tuning process for $\\alpha$ proceeds roughly as follows:\n",
    "1. we specify a list of candidate values for $\\alpha$, \n",
    "2. for each choice of $\\alpha$, we learn a predictor that minimizes the regularized cost function\n",
    "3. for each choice of $\\alpha$, we validate the trained predictor $h^{(\\alpha)}_{\\rm opt}$ by computing the validation error\n",
    "\n",
    "\\begin{equation}\n",
    "E_{\\rm val}^{(\\alpha)} = (1/m_{\\rm v}) \\sum_{\\big(\\mathbf{x}^{(i)},y^{(i)}\\big) \\in \\mathbb{X}^{(v)}} \\mathcal L \\big( (x^{(i)} y^{(i)}), h)\\big).\n",
    "\\end{equation}\n",
    "\n",
    "4. We select the value of $\\alpha$ with smallest validation error to be used in our final model \n",
    "5. We evaluate the final model on a test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2760bc3b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9ef0da427faccaddbd2eb8c9d01fcd46",
     "grade": false,
     "grade_id": "cell-c6cdeae19063c33b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a id='St1'></a>\n",
    "<div class=\" alert alert-warning\">\n",
    "    <h3><b>Student task.</b> Hyperparameter tuning.</h3>  \n",
    "\n",
    "In this exercise we will use the following ANN for Fashion-MNIST classification dataset:\n",
    "    \n",
    "- Dense layer with 128 units, ReLU activation and $L2$ regularization for model weights\n",
    "- Dense layer with 64 units, ReLU activation and $L2$ regularization for model weights\n",
    "- Dense layer with 32 units, ReLU activation and $L2$ regularization for model weights\n",
    "- Dense output layer with 10 units and softmax activation function\n",
    "    \n",
    "Use optimizer - RMSprop, loss - `sparse_categorical_crossentropy` and metrics -  `sparse_categorical_accuracy`. \n",
    "Training parameters:\n",
    "`history = model.fit(X_trainval, y_trainval, validation_split=0.2, batch_size=32, epochs=20)`\n",
    "\n",
    "Your task is to implement a function `L2_hyperparam()`. The input parameter of this function `l2` is a list of regularization hyperparameter values $\\alpha$. This function should, for each entry of that list:\n",
    "    \n",
    "- create a new ANN Sequential model (see instructions above). In this step, you need to pass the $\\alpha$ value to the layer's $L2$ regularizer.\n",
    "- compile the model\n",
    "- train the model. Store history object for each model in a list `history_log`.\n",
    "- compute the accuracy obtained on the test set and add this value to the list `test_acc`\n",
    "    \n",
    "After completing the above steps for each value in the list `l2`, the function should return lists `history_log` and  `test_acc`.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "05e36f22",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ad2eae65eb0f98c401bdb4ffb6cb1f55",
     "grade": false,
     "grade_id": "cell-77a811770bb9dc63",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# list of L2 regularization scaling factor values\n",
    "l2 = [1e-1, 1e-3, 0]\n",
    "\n",
    "def L2_hyperparam(l2):\n",
    "    # for reproducibility\n",
    "    np.random.seed(1)\n",
    "    tf.random.set_seed(1)\n",
    "\n",
    "    history_log = [] # list to store training history\n",
    "    test_acc = [] # list to store test accuracies\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    # iterate list `l2`\n",
    "    for alpha in l2:\n",
    "        # Create a new ANN Sequential model\n",
    "        model = keras.Sequential([layers.Dense(128, activation='relu',input_shape=(784,),\n",
    "                                                kernel_regularizer = regularizers.L2(alpha)),\n",
    "                                    layers.Dense(64, activation='relu', \n",
    "                                                kernel_regularizer = regularizers.L2(alpha)),\n",
    "                                    layers.Dense(32, activation='relu',\n",
    "                                                kernel_regularizer = regularizers.L2(alpha)),\n",
    "                                    layers.Dense(10, activation='softmax')\n",
    "                                ])\n",
    "        # Compile the model\n",
    "        model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer='RMSprop',\n",
    "              metrics=[\"sparse_categorical_accuracy\"])\n",
    "        \n",
    "        # Train the model   \n",
    "        history = model.fit(X_trainval, y_trainval, validation_split=0.2, batch_size=32, epochs=20)\n",
    "        history_log.append(history)\n",
    "        \n",
    "        # Compute the accuracy\n",
    "        _, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "        test_acc.append(accuracy)\n",
    "        \n",
    "    return history_log, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cc604370",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "55d239f9f6dad1ee9904845d7bb968af",
     "grade": false,
     "grade_id": "cell-e81bba2646a2524d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 4.7896 - sparse_categorical_accuracy: 0.5508 - val_loss: 1.8568 - val_sparse_categorical_accuracy: 0.6569\n",
      "Epoch 2/20\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 1.7527 - sparse_categorical_accuracy: 0.6135 - val_loss: 1.7045 - val_sparse_categorical_accuracy: 0.6109\n",
      "Epoch 3/20\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 1.5896 - sparse_categorical_accuracy: 0.6572 - val_loss: 1.5572 - val_sparse_categorical_accuracy: 0.6600\n",
      "Epoch 4/20\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 1.4873 - sparse_categorical_accuracy: 0.6827 - val_loss: 1.4319 - val_sparse_categorical_accuracy: 0.7041\n",
      "Epoch 5/20\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 1.4231 - sparse_categorical_accuracy: 0.6954 - val_loss: 1.3799 - val_sparse_categorical_accuracy: 0.7147\n",
      "Epoch 6/20\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 1.3722 - sparse_categorical_accuracy: 0.7013 - val_loss: 1.3227 - val_sparse_categorical_accuracy: 0.7166\n",
      "Epoch 7/20\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 1.3349 - sparse_categorical_accuracy: 0.7034 - val_loss: 1.2883 - val_sparse_categorical_accuracy: 0.7175\n",
      "Epoch 8/20\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 1.3018 - sparse_categorical_accuracy: 0.7145 - val_loss: 1.3085 - val_sparse_categorical_accuracy: 0.6978\n",
      "Epoch 9/20\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 1.2762 - sparse_categorical_accuracy: 0.7119 - val_loss: 1.2919 - val_sparse_categorical_accuracy: 0.7075\n",
      "Epoch 10/20\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 1.2529 - sparse_categorical_accuracy: 0.7141 - val_loss: 1.2232 - val_sparse_categorical_accuracy: 0.7172\n",
      "Epoch 11/20\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 1.2321 - sparse_categorical_accuracy: 0.7186 - val_loss: 1.2102 - val_sparse_categorical_accuracy: 0.7134\n",
      "Epoch 12/20\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 1.2142 - sparse_categorical_accuracy: 0.7251 - val_loss: 1.1800 - val_sparse_categorical_accuracy: 0.7300\n",
      "Epoch 13/20\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 1.1963 - sparse_categorical_accuracy: 0.7260 - val_loss: 1.1828 - val_sparse_categorical_accuracy: 0.7306\n",
      "Epoch 14/20\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 1.1814 - sparse_categorical_accuracy: 0.7293 - val_loss: 1.1542 - val_sparse_categorical_accuracy: 0.7397\n",
      "Epoch 15/20\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 1.1716 - sparse_categorical_accuracy: 0.7291 - val_loss: 1.1548 - val_sparse_categorical_accuracy: 0.7300\n",
      "Epoch 16/20\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 1.1576 - sparse_categorical_accuracy: 0.7297 - val_loss: 1.2059 - val_sparse_categorical_accuracy: 0.7072\n",
      "Epoch 17/20\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 1.1463 - sparse_categorical_accuracy: 0.7307 - val_loss: 1.1794 - val_sparse_categorical_accuracy: 0.7100\n",
      "Epoch 18/20\n",
      "400/400 [==============================] - 1s 4ms/step - loss: 1.1365 - sparse_categorical_accuracy: 0.7344 - val_loss: 1.1337 - val_sparse_categorical_accuracy: 0.7322\n",
      "Epoch 19/20\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 1.1287 - sparse_categorical_accuracy: 0.7379 - val_loss: 1.1355 - val_sparse_categorical_accuracy: 0.7397\n",
      "Epoch 20/20\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 1.1211 - sparse_categorical_accuracy: 0.7395 - val_loss: 1.1940 - val_sparse_categorical_accuracy: 0.6875\n",
      "Epoch 1/20\n",
      "400/400 [==============================] - 3s 5ms/step - loss: 0.9704 - sparse_categorical_accuracy: 0.7297 - val_loss: 0.7809 - val_sparse_categorical_accuracy: 0.7953\n",
      "Epoch 2/20\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.7018 - sparse_categorical_accuracy: 0.8144 - val_loss: 0.6873 - val_sparse_categorical_accuracy: 0.8184\n",
      "Epoch 3/20\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.6344 - sparse_categorical_accuracy: 0.8277 - val_loss: 0.6989 - val_sparse_categorical_accuracy: 0.8106\n",
      "Epoch 4/20\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.5931 - sparse_categorical_accuracy: 0.8404 - val_loss: 0.5898 - val_sparse_categorical_accuracy: 0.8366\n",
      "Epoch 5/20\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.5616 - sparse_categorical_accuracy: 0.8477 - val_loss: 0.6093 - val_sparse_categorical_accuracy: 0.8178\n",
      "Epoch 6/20\n",
      "400/400 [==============================] - 1s 4ms/step - loss: 0.5410 - sparse_categorical_accuracy: 0.8508 - val_loss: 0.5558 - val_sparse_categorical_accuracy: 0.8462\n",
      "Epoch 7/20\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.5231 - sparse_categorical_accuracy: 0.8564 - val_loss: 0.5353 - val_sparse_categorical_accuracy: 0.8466\n",
      "Epoch 8/20\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 0.5102 - sparse_categorical_accuracy: 0.8617 - val_loss: 0.5167 - val_sparse_categorical_accuracy: 0.8569\n",
      "Epoch 9/20\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.4965 - sparse_categorical_accuracy: 0.8632 - val_loss: 0.5795 - val_sparse_categorical_accuracy: 0.8328\n",
      "Epoch 10/20\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 0.4855 - sparse_categorical_accuracy: 0.8640 - val_loss: 0.5494 - val_sparse_categorical_accuracy: 0.8378\n",
      "Epoch 11/20\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 0.4735 - sparse_categorical_accuracy: 0.8702 - val_loss: 0.5269 - val_sparse_categorical_accuracy: 0.8444\n",
      "Epoch 12/20\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 0.4649 - sparse_categorical_accuracy: 0.8689 - val_loss: 0.5742 - val_sparse_categorical_accuracy: 0.8284\n",
      "Epoch 13/20\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 0.4593 - sparse_categorical_accuracy: 0.8714 - val_loss: 0.5665 - val_sparse_categorical_accuracy: 0.8328\n",
      "Epoch 14/20\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 0.4507 - sparse_categorical_accuracy: 0.8718 - val_loss: 0.5182 - val_sparse_categorical_accuracy: 0.8534\n",
      "Epoch 15/20\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 0.4493 - sparse_categorical_accuracy: 0.8742 - val_loss: 0.4973 - val_sparse_categorical_accuracy: 0.8575\n",
      "Epoch 16/20\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.4355 - sparse_categorical_accuracy: 0.8763 - val_loss: 0.5404 - val_sparse_categorical_accuracy: 0.8397\n",
      "Epoch 17/20\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.4314 - sparse_categorical_accuracy: 0.8766 - val_loss: 0.4879 - val_sparse_categorical_accuracy: 0.8544\n",
      "Epoch 18/20\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 0.4259 - sparse_categorical_accuracy: 0.8791 - val_loss: 0.4950 - val_sparse_categorical_accuracy: 0.8569\n",
      "Epoch 19/20\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.4245 - sparse_categorical_accuracy: 0.8837 - val_loss: 0.5006 - val_sparse_categorical_accuracy: 0.8509\n",
      "Epoch 20/20\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 0.4183 - sparse_categorical_accuracy: 0.8823 - val_loss: 0.4820 - val_sparse_categorical_accuracy: 0.8587\n",
      "Epoch 1/20\n",
      "400/400 [==============================] - 3s 5ms/step - loss: 0.7238 - sparse_categorical_accuracy: 0.7439 - val_loss: 0.5381 - val_sparse_categorical_accuracy: 0.8059\n",
      "Epoch 2/20\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 0.4789 - sparse_categorical_accuracy: 0.8211 - val_loss: 0.4697 - val_sparse_categorical_accuracy: 0.8206\n",
      "Epoch 3/20\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 0.4245 - sparse_categorical_accuracy: 0.8459 - val_loss: 0.4919 - val_sparse_categorical_accuracy: 0.8263\n",
      "Epoch 4/20\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 0.3879 - sparse_categorical_accuracy: 0.8577 - val_loss: 0.4035 - val_sparse_categorical_accuracy: 0.8491\n",
      "Epoch 5/20\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.3598 - sparse_categorical_accuracy: 0.8675 - val_loss: 0.4445 - val_sparse_categorical_accuracy: 0.8400\n",
      "Epoch 6/20\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.3402 - sparse_categorical_accuracy: 0.8732 - val_loss: 0.3889 - val_sparse_categorical_accuracy: 0.8656\n",
      "Epoch 7/20\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 0.3205 - sparse_categorical_accuracy: 0.8827 - val_loss: 0.4050 - val_sparse_categorical_accuracy: 0.8581\n",
      "Epoch 8/20\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 0.3076 - sparse_categorical_accuracy: 0.8875 - val_loss: 0.3750 - val_sparse_categorical_accuracy: 0.8706\n",
      "Epoch 9/20\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.2969 - sparse_categorical_accuracy: 0.8883 - val_loss: 0.4493 - val_sparse_categorical_accuracy: 0.8541\n",
      "Epoch 10/20\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 0.2840 - sparse_categorical_accuracy: 0.8916 - val_loss: 0.4115 - val_sparse_categorical_accuracy: 0.8566\n",
      "Epoch 11/20\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 0.2718 - sparse_categorical_accuracy: 0.9020 - val_loss: 0.4344 - val_sparse_categorical_accuracy: 0.8612\n",
      "Epoch 12/20\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 0.2610 - sparse_categorical_accuracy: 0.9023 - val_loss: 0.4565 - val_sparse_categorical_accuracy: 0.8569\n",
      "Epoch 13/20\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 0.2529 - sparse_categorical_accuracy: 0.9080 - val_loss: 0.4686 - val_sparse_categorical_accuracy: 0.8525\n",
      "Epoch 14/20\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 0.2476 - sparse_categorical_accuracy: 0.9091 - val_loss: 0.5039 - val_sparse_categorical_accuracy: 0.8572\n",
      "Epoch 15/20\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 0.2435 - sparse_categorical_accuracy: 0.9102 - val_loss: 0.4805 - val_sparse_categorical_accuracy: 0.8678\n",
      "Epoch 16/20\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 0.2348 - sparse_categorical_accuracy: 0.9114 - val_loss: 0.4745 - val_sparse_categorical_accuracy: 0.8628\n",
      "Epoch 17/20\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 0.2249 - sparse_categorical_accuracy: 0.9138 - val_loss: 0.4572 - val_sparse_categorical_accuracy: 0.8631\n",
      "Epoch 18/20\n",
      "400/400 [==============================] - 1s 4ms/step - loss: 0.2202 - sparse_categorical_accuracy: 0.9167 - val_loss: 0.5670 - val_sparse_categorical_accuracy: 0.8522\n",
      "Epoch 19/20\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 0.2182 - sparse_categorical_accuracy: 0.9204 - val_loss: 0.5113 - val_sparse_categorical_accuracy: 0.8669\n",
      "Epoch 20/20\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2176 - sparse_categorical_accuracy: 0.9202 - val_loss: 0.5246 - val_sparse_categorical_accuracy: 0.8678\n",
      "[0.6741999983787537, 0.8529999852180481, 0.8600000143051147]\n",
      "CPU times: user 5min 16s, sys: 1min 6s, total: 6min 22s\n",
      "Wall time: 1min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "# call  L2_hyperparam() function\n",
    "history_log, test_acc = L2_hyperparam(l2)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8d420a91",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7e892ab91965a0e6f3f4d7253993cd7f",
     "grade": false,
     "grade_id": "cell-a44d3c77a7ed7357",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1,3, sharey=True, figsize=(12,4))\n",
    "title = [str(alpha_l2) for alpha_l2 in l2]\n",
    "\n",
    "ax = axes.flat\n",
    "for i in range(len(history_log)):\n",
    "    ax[i].plot(history_log[i].history['sparse_categorical_accuracy'])\n",
    "    ax[i].plot(history_log[i].history['val_sparse_categorical_accuracy'])\n",
    "    ax[i].spines[\"top\"].set_visible(False)\n",
    "    ax[i].spines[\"right\"].set_visible(False)\n",
    "    ax[i].set_title(title[i], fontsize=18)\n",
    "    ax[i].grid()\n",
    "\n",
    "ax[0].set_xlabel('epoch', fontsize=14)\n",
    "ax[0].set_ylabel('Loss', fontsize=14)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.legend(['train', 'val'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d2de2018",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "81c15637ad4eef66392c0dc888042c38",
     "grade": false,
     "grade_id": "cell-ba33f8a0c1f4c0c9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity check tests passed!\n"
     ]
    }
   ],
   "source": [
    "# Sanity check\n",
    "\n",
    "assert len(test_acc)==3, 'Length of list `test_acc` should be equal to 3!'\n",
    "# check accuracy values\n",
    "assert test_acc[0]>=0.65 or isclose(test_accuracy, 0.65, abs_tol=2.5e-2), \"Accuracy is too low!\"\n",
    "assert test_acc[1]>=0.83 or isclose(test_accuracy, 0.83, abs_tol=2.5e-2), \"Accuracy is too low!\"\n",
    "assert test_acc[2]>=0.83 or isclose(test_accuracy, 0.83, abs_tol=2.5e-2), \"Accuracy is too low!\"\n",
    "print('Sanity check tests passed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e953bf4e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e8d6a5c4b0937f46b09693b4f2c1c4c0",
     "grade": true,
     "grade_id": "cell-e4269af6fa2561b6",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is for tests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901f60d5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cc1155bc54ccb30d2afc751def51841f",
     "grade": false,
     "grade_id": "cell-9d62103b87d1cbf5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a id='St1'></a>\n",
    "<div class=\" alert alert-warning\">\n",
    "    <h3><b>Student task.</b> Build ANN with Dropout Layers + L2 regularization.</h3>  \n",
    "\n",
    "Although in our case the benefits of using regularization methods may not be evident, for large deep learning models it is quite common to use several regularization methods together.\n",
    "\n",
    "In this task we will combine two regularization methods - $L2$ regularization of model's weights and dropout. Build the following ANN: \n",
    "    \n",
    "- Dense layer with 128 units, ReLU activation and $L2$ regularization for model weights\n",
    "- Dropout layer\n",
    "- Dense layer with 64 units, ReLU activation and $L2$ regularization for model weights\n",
    "- Dropout layer\n",
    "- Dense layer with 32 units, ReLU activation and $L2$ regularization for model weights\n",
    "- Dropout layer\n",
    "- Dense layer with 10 units and softmax activation function\n",
    "    \n",
    "Use optimizer - RMSprop, loss - `sparse_categorical_crossentropy` and metrics -  `sparse_categorical_accuracy`. \n",
    "Training parameters:\n",
    "`history = model.fit(X_trainval, y_trainval, validation_split=0.2, batch_size=32, epochs=20)`\n",
    "    \n",
    "- Save model as ` model_dropout_l2.h5`\n",
    "   \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdf5f59",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c2e554a1d5ca8cec24eada636fced992",
     "grade": false,
     "grade_id": "cell-3e54c40f8b95e32d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\" alert alert-danger\">\n",
    "    <h3 align='center'>Test accuracy should be $\\geq$ 0.83 formodel_dropout_l2.</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fe57f869",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c9cc69092bb48315ec38602d97b44224",
     "grade": false,
     "grade_id": "cell-213fc0754f58fb18",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# dropout rate\n",
    "drate = 0.1\n",
    "# alpha value for L2 regularization\n",
    "alpha_l2 = 1e-4\n",
    "\n",
    "if training==True:\n",
    "    # YOUR CODE HERE\n",
    "    model_dropout_l2 = keras.Sequential([layers.Dense(128, activation='relu',input_shape=(784,),\n",
    "                                         kernel_regularizer = regularizers.L2(alpha_l2)),\n",
    "                                         layers.Dropout(drate),\n",
    "                                         \n",
    "                                         layers.Dense(64, activation='relu', \n",
    "                                         kernel_regularizer = regularizers.L2(alpha_l2)),\n",
    "                                         layers.Dropout(drate),\n",
    "                                         \n",
    "                                         layers.Dense(32, activation='relu',\n",
    "                                         kernel_regularizer = regularizers.L2(alpha_l2)),\n",
    "                                         layers.Dropout(drate),\n",
    "                                    \n",
    "                                         layers.Dense(10, activation='softmax')\n",
    "                                ])\n",
    "    model_dropout_l2.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer='RMSprop',\n",
    "              metrics=[\"sparse_categorical_accuracy\"])\n",
    "    \n",
    "    history = model_dropout_l2.fit(X_trainval, y_trainval, validation_split=0.2, batch_size=32, epochs=20)\n",
    "    model_dropout_l2.save(\"model_dropout_l2.h5\")\n",
    "else:\n",
    "    model_dropout_l2 = tf.keras.models.load_model(\"model_dropout_l2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ecac0c94",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "33d6977708547009af7a57dfbb99eeae",
     "grade": false,
     "grade_id": "cell-545ea3210cb58a57",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropout - Accuracy on test dataset:  0.8357\n"
     ]
    }
   ],
   "source": [
    "_, test_accuracy = model_dropout_l2.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Dropout - Accuracy on test dataset: {test_accuracy: .4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ad06e056",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "23625f3006fa51f7d388fef00a83ae8c",
     "grade": false,
     "grade_id": "cell-ec5f884cc815c7a3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check\n",
    "\n",
    "assert len(model_dropout_l2.layers) == 7, \"There should be 7 layers!\"\n",
    "model_dropout_l2.layers[0].kernel_regularizer.l2 == regularizers.L2(alpha_l2).l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b7d019c6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eae7e29dcb26fddd32fae25e9aef9b80",
     "grade": true,
     "grade_id": "cell-e2ea32b554b90200",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# cell for hidden test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3de4bf53",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "31f4fabd6e45b341572bce257608aa2f",
     "grade": false,
     "grade_id": "cell-9244d5f96abb7c6d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Sanity checks\n",
    "# check that all models from student tasks are saved\n",
    "\n",
    "import os.path\n",
    "\n",
    "# check that models  are saved\n",
    "assert os.path.isfile('model_base.h5')==True, \"Model `model_base` is not saved!\"\n",
    "assert os.path.isfile('model_data_aug.h5')==True, \"Model `model_data_aug` is not saved!\"\n",
    "assert os.path.isfile('model_noise.h5')==True, \"Model `model_noise` is not saved!\"\n",
    "assert os.path.isfile('model_dropout.h5')==True, \"Model `model_dropout` is not saved!\"\n",
    "assert os.path.isfile('model_dropout_l2.h5')==True, \"Model `model_dropout_l2` is not saved!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbc0ba2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "325.404388px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
